{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, normalize, MinMaxScaler\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from models import build_model2, cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./Music Genre Classification/\"            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor():\n",
    "    def __init__(self, datadir ,n_mfccs=13, n_fft=1024, hop_length=512, n_splits=10, hop=2):\n",
    "        self.n_mfccs = n_mfccs\n",
    "        self.hop_length = hop_length\n",
    "        self.MFCCs = []\n",
    "        self.labels = []\n",
    "        self.datadir = datadir\n",
    "        self.hop =  hop\n",
    "        self.n_fft = n_fft\n",
    "        self.n_splits = n_splits\n",
    "    \n",
    "    def extract_features(self):\n",
    "        for path, subdirs, files in os.walk(self.datadir):\n",
    "            for file in files:\n",
    "                filepath = os.path.join(path, file)\n",
    "                if file.endswith(\".wav\"):\n",
    "                    try:\n",
    "                        audio, sr = sf.read(filepath)\n",
    "                        genre = os.path.basename(path)\n",
    "                        duration = int(audio.shape[0] / sr)\n",
    "                        frame = int(duration / self.n_splits)\n",
    "                        for i in range(0, duration, self.hop):   \n",
    "                            MFCC = librosa.feature.mfcc(y=audio[i*sr: (i+frame)*sr], n_mfcc=self.n_mfccs, n_fft=self.n_fft, hop_length=self.hop_length)\n",
    "                            if MFCC.shape != (13, 130): continue\n",
    "                            self.MFCCs.append(MFCC)\n",
    "                            self.labels.append(genre)        \n",
    "                    except Exception as e:\n",
    "                        print(\"Error encountered while parsing file: \", filepath)\n",
    "                        print(e)\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  ./Music Genre Classification/Train/jazz/jazz.00054.wav\n",
      "Error opening './Music Genre Classification/Train/jazz/jazz.00054.wav': Format not recognised.\n"
     ]
    }
   ],
   "source": [
    "data_extractor = FeatureExtractor(data_dir)\n",
    "data_extractor.extract_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " 'pop',\n",
       " ...]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_extractor.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_avg_mfccs = {genre: [] for genre in set(data_extractor.labels)}\n",
    "for i in range(len(data_extractor.labels)):\n",
    "    avg_mfccs = np.mean(data_extractor.MFCCs[i], axis=1)\n",
    "    music_avg_mfccs[data_extractor.labels[i]].append(avg_mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['country', 'classical', 'jazz', 'hiphop', 'metal', 'reggae', 'disco', 'pop', 'rock', 'blues'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_avg_mfccs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [music_avg_mfccs[genre] for genre in music_avg_mfccs.keys()]\n",
    "genres = music_avg_mfccs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs_dict = {i: [] for i in range(1, data_extractor.n_mfccs+1)}\n",
    "for i in range(len(genres)):\n",
    "    test = np.array(X[i])\n",
    "    for num in range(1, data_extractor.n_mfccs+1):\n",
    "        mfccs_dict[num].append(test[:, (num-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(mfccs_dict[1], patch_artist=True)\n",
    "plt.xticks([i for i in range(1, len(genres)+1)], genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(mfccs_dict[2], patch_artist=True)\n",
    "plt.xticks([i for i in range(1, len(genres)+1)], genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(mfccs_dict[3], patch_artist=True)\n",
    "plt.xticks([i for i in range(1, len(genres)+1)], genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(mfccs_dict[4], patch_artist=True)\n",
    "plt.xticks([i for i in range(1, len(genres)+1)], genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(mfccs_dict[5], patch_artist=True)\n",
    "plt.xticks([i for i in range(1, len(genres)+1)], genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(mfccs_dict[6], patch_artist=True)\n",
    "plt.xticks([i for i in range(1, len(genres)+1)], genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(mfccs_dict[7], patch_artist=True)\n",
    "plt.xticks([i for i in range(1, len(genres)+1)], genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(mfccs_dict[8], patch_artist=True)\n",
    "plt.xticks([i for i in range(1, len(genres)+1)], genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(mfccs_dict[9], patch_artist=True)\n",
    "plt.xticks([i for i in range(1, len(genres)+1)], genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(mfccs_dict[10], patch_artist=True)\n",
    "plt.xticks([i for i in range(1, len(genres)+1)], genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_avg_mfccs['rock'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_classes):\n",
    "    \n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(256, activation='relu', input_shape=input_shape, kernel_regularizer=regularizers.l2(0.001)),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "def cnn_model(input_shape, num_classes):\n",
    "    model_cnn = Sequential()\n",
    "\n",
    "    # 1st conv layer\n",
    "    model_cnn.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model_cnn.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model_cnn.add(BatchNormalization())\n",
    "\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model_cnn.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer='he_uniform',kernel_regularizer=regularizers.l2(0.0001)))\n",
    "    model_cnn.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model_cnn.add(BatchNormalization())\n",
    "    model_cnn.add(Dropout(0.3))\n",
    "\n",
    "    # 3rd conv layer\n",
    "    model_cnn.add(Conv2D(128, (2, 2), activation='relu',kernel_initializer='he_uniform',kernel_regularizer=regularizers.l2(0.0001)))\n",
    "    model_cnn.add(MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model_cnn.add(BatchNormalization())\n",
    "    model_cnn.add(Dropout(0.3))\n",
    "\n",
    "    # flatten output and feed it into dense layer\n",
    "    model_cnn.add(Flatten())\n",
    "    model_cnn.add(Dense(128, activation='relu',kernel_initializer='he_uniform',kernel_regularizer=regularizers.l2(0.0001)))\n",
    "    model_cnn.add(BatchNormalization())\n",
    "    model_cnn.add(Dropout(0.3))\n",
    "\n",
    "    # output layer\n",
    "    model_cnn.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LabelEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data_extractor.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "ANN = build_model((1, 13)\n",
    "                , 10)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "ANN.compile(loss=CategoricalCrossentropy(), optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "training_labels = []\n",
    "for genre in music_avg_mfccs.keys():\n",
    "    for i in range(len(music_avg_mfccs[genre])):\n",
    "        training_data.append(music_avg_mfccs[genre][i])\n",
    "        training_labels.append(label_encoder.transform([genre])[0])\n",
    "        \n",
    "training_data = np.array(training_data)\n",
    "training_labels = np.array(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "normalized_training_data = scaler.fit_transform(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = to_categorical(training_labels)\n",
    "training_labels = (training_labels[:, np.newaxis, :])\n",
    "normalized_training_data = (normalized_training_data[:, np.newaxis, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(normalized_training_data, training_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8892, 1, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN.fit(X_train, y_train, epochs=100, validation_split=0.3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.7877 - loss: 0.9295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9276933073997498, 0.786796510219574]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN.save('model4.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 - 0s - 3ms/step - accuracy: 0.8849 - loss: 0.7054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7053617238998413, 0.8848921060562134]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN.load_weights('model5.keras')\n",
    "ANN.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step\n"
     ]
    }
   ],
   "source": [
    "y_predict_categorical = ANN.predict(X_test)\n",
    "y_predict = y_predict_categorical.reshape((1, len(X_test), 10))[0]\n",
    "y_test_reshaped = y_test.reshape((1, len(X_test), 10))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = np.argmax(y_predict, axis=1)\n",
    "y_test_reshaped = np.argmax(y_test_reshaped, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       224\n",
      "           1       0.95      0.96      0.96       224\n",
      "           2       0.86      0.84      0.85       219\n",
      "           3       0.83      0.85      0.84       232\n",
      "           4       0.83      0.85      0.84       219\n",
      "           5       0.92      0.90      0.91       220\n",
      "           6       0.93      0.91      0.92       235\n",
      "           7       0.89      0.92      0.90       224\n",
      "           8       0.89      0.87      0.88       201\n",
      "           9       0.87      0.81      0.84       226\n",
      "\n",
      "    accuracy                           0.88      2224\n",
      "   macro avg       0.89      0.88      0.88      2224\n",
      "weighted avg       0.89      0.88      0.88      2224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_reshaped, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.transform(['classical', 'blues', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPredictior():\n",
    "    def __init__(self, model_path, input_shape, num_classes, n_mfccs=13, n_fft=1024, hop_length=512):\n",
    "        # model path for buiding model\n",
    "        self.model_path = model_path\n",
    "        self.input_shape = input_shape\n",
    "        self.n_mfccs = n_mfccs\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "    # Build DNN\n",
    "    def build_dnn_model(self):\n",
    "        model = build_model(self.input_shape, self.num_classes)\n",
    "        return model\n",
    "    \n",
    "    # Build CNN\n",
    "    def build_cnn_model(self):\n",
    "        model = cnn_model(self.input_shape, self.num_classes)\n",
    "        return model\n",
    "    \n",
    "    def predict(self, filepath, n_splits=10, hop=2):\n",
    "        # Load File path and model weights\n",
    "        try:\n",
    "            # Load song\n",
    "            audio, sr = sf.read(filepath)\n",
    "            # Calulate duration\n",
    "            duration = int(audio.shape[0] / sr)\n",
    "            # Window size for spliting the song into smaller bits\n",
    "            frame = int(duration / n_splits)\n",
    "            # build and load model weights\n",
    "            model = self.build_dnn_model()\n",
    "            model.load_weights(self.model_path)\n",
    "        except Exception as e:\n",
    "            return\n",
    "        \n",
    "        # cache genre predictions\n",
    "        genre_predictions = {}\n",
    " \n",
    "        for i in range(0, duration, hop):\n",
    "            # Extract MFCC of a window\n",
    "            MFCC = librosa.feature.mfcc(y=audio[i*sr: (i+frame)*sr], n_mfcc=self.n_mfccs, n_fft=self.n_fft, hop_length=self.hop_length)\n",
    "            # Calculate Mean MFCC across time axis\n",
    "            MFCC = np.mean(MFCC, axis=1)\n",
    "            # Add an axis for giving model as a batch size of 1\n",
    "            MFCC = MFCC[np.newaxis, :]\n",
    "            # scale model using Min Max scaler using all ready used in training\n",
    "            MFCC = scaler.transform(MFCC)\n",
    "            # predict\n",
    "            prediction = model.predict(MFCC,  verbose=0)\n",
    "            prediction = np.argmax(prediction, axis=1)\n",
    "            genre = label_encoder.inverse_transform(prediction)\n",
    "            # update frequency of genre predicted\n",
    "            genre_predictions[genre[0]] = genre_predictions.get(genre[0], 0) + 1\n",
    "    \n",
    "        return genre_predictions\n",
    "    \n",
    "    \n",
    "    def cnn_predict(self, filepath, n_splits=10, hop=2):\n",
    "        try:\n",
    "            # Load song\n",
    "            audio, sr = sf.read(filepath)\n",
    "            # Calulate duration\n",
    "            duration = int(audio.shape[0] / sr)\n",
    "            # Window size for spliting the song into smaller bits\n",
    "            frame = int(duration / n_splits)\n",
    "            # build and load model weights\n",
    "            model = self.build_cnn_model()\n",
    "            model.load_weights(self.model_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return\n",
    "        \n",
    "        \n",
    "        genre_predictions = {}\n",
    "        for i in range(0, duration, hop):\n",
    "            try:\n",
    "                # Extract model\n",
    "                MFCC = librosa.feature.mfcc(y=audio[i*sr: (i+frame)*sr], n_mfcc=self.n_mfccs, n_fft=self.n_fft, hop_length=self.hop_length)\n",
    "                # add a axis at beginning for batch size and other axis for CNN num channels \n",
    "                MFCC = MFCC[np.newaxis, :, :, np.newaxis]\n",
    "                # predict\n",
    "                prediction = model.predict(MFCC,  verbose=0)\n",
    "                prediction = np.argmax(prediction, axis=1)\n",
    "                genre = label_encoder.inverse_transform(prediction)\n",
    "                # update frequency of genre predicted\n",
    "                genre_predictions[genre[0]] = genre_predictions.get(genre[0], 0) + 1\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        return genre_predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN model predictor\n",
    "predictore = ModelPredictior(model_path='model5.keras', input_shape=(13,), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rock': 12, 'classical': 1, 'jazz': 2}\n"
     ]
    }
   ],
   "source": [
    "# Example How the return value looks like \n",
    "file_path = \"./Music Genre Classification/Train/rock/rock.00023.wav\"\n",
    "predicted_genres = predictore.predict(file_path)\n",
    "print(predicted_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample larger than population or is negative\n",
      "Sample larger than population or is negative\n"
     ]
    }
   ],
   "source": [
    "# randomly sample 20 full-songs from the given data set\n",
    "import random\n",
    "test_files = []\n",
    "n_samples = 20\n",
    "for path, subdirs, files in os.walk(data_dir):\n",
    "    try:\n",
    "        random_files = random.sample(files, n_samples)\n",
    "        for file in random_files:\n",
    "            filepath = os.path.join(path, file)\n",
    "            if file.endswith(\".wav\"):\n",
    "                test_files.append(filepath)     \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a dictionary it gives max genre\n",
    "def max_freq_genre(genres):\n",
    "    max_freq = 0\n",
    "    max_genre = ''\n",
    "    for genre in genres.keys():\n",
    "        if genres[genre] > max_freq:\n",
    "            max_freq = genres[genre]\n",
    "            max_genre = genre\n",
    "    return max_genre\n",
    "\n",
    "# for DNN predict the genre of entire by giving to the predictor\n",
    "predictions = []\n",
    "actual = []\n",
    "for file in test_files:\n",
    "    try:\n",
    "        predicted_genres = predictore.predict(file)\n",
    "        predictions.append(max_freq_genre(predicted_genres))\n",
    "        actual.append(file.split(\"/\")[-2])\n",
    "    except Exception as e:\n",
    "        print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       1.00      0.95      0.97        20\n",
      "   classical       1.00      1.00      1.00        20\n",
      "     country       0.95      1.00      0.98        20\n",
      "       disco       0.95      0.95      0.95        20\n",
      "      hiphop       0.95      0.95      0.95        20\n",
      "        jazz       1.00      1.00      1.00        20\n",
      "       metal       0.95      1.00      0.98        20\n",
      "         pop       0.95      0.95      0.95        20\n",
      "      reggae       1.00      0.95      0.97        20\n",
      "        rock       0.90      0.90      0.90        20\n",
      "\n",
      "    accuracy                           0.96       200\n",
      "   macro avg       0.97      0.97      0.96       200\n",
      "weighted avg       0.97      0.96      0.96       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report for DNN using the full-songs sampled\n",
    "print(classification_report(actual, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_36          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_37          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_38          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">245,888</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_39          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_27 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_36          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_28 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_37          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_29 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_38          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m245,888\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_39          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">300,298</span> (1.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m300,298\u001b[0m (1.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">299,594</span> (1.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m299,594\u001b[0m (1.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn = cnn_model(input_shape=(13, 130, 1), num_classes=10)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the Labels\n",
    "y = label_encoder.transform(data_extractor.labels)\n",
    "# Load the MFCCs Extracted\n",
    "X = data_extractor.MFCCs\n",
    "# split the data-set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# add the last dimension for CNN\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_val = np.expand_dims(X_val, axis=-1)\n",
    "X = np.expand_dims(X, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode the labels\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y = to_categorical(y)\n",
    "# compile\n",
    "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "63/63 - 4s - 65ms/step - accuracy: 0.4726 - loss: 1.7000 - val_accuracy: 0.2708 - val_loss: 4.4640\n",
      "Epoch 2/30\n",
      "63/63 - 3s - 49ms/step - accuracy: 0.6252 - loss: 1.1260 - val_accuracy: 0.3831 - val_loss: 2.3114\n",
      "Epoch 3/30\n",
      "63/63 - 3s - 48ms/step - accuracy: 0.6898 - loss: 0.9482 - val_accuracy: 0.6236 - val_loss: 1.1409\n",
      "Epoch 4/30\n",
      "63/63 - 3s - 46ms/step - accuracy: 0.7291 - loss: 0.8394 - val_accuracy: 0.6775 - val_loss: 0.9767\n",
      "Epoch 5/30\n",
      "63/63 - 3s - 47ms/step - accuracy: 0.7604 - loss: 0.7531 - val_accuracy: 0.7584 - val_loss: 0.8017\n",
      "Epoch 6/30\n",
      "63/63 - 3s - 46ms/step - accuracy: 0.7859 - loss: 0.6858 - val_accuracy: 0.7461 - val_loss: 0.7982\n",
      "Epoch 7/30\n",
      "63/63 - 3s - 49ms/step - accuracy: 0.8017 - loss: 0.6330 - val_accuracy: 0.7573 - val_loss: 0.7508\n",
      "Epoch 8/30\n",
      "63/63 - 3s - 49ms/step - accuracy: 0.8185 - loss: 0.5819 - val_accuracy: 0.6685 - val_loss: 0.9926\n",
      "Epoch 9/30\n",
      "63/63 - 3s - 47ms/step - accuracy: 0.8360 - loss: 0.5458 - val_accuracy: 0.7506 - val_loss: 0.7593\n",
      "Epoch 10/30\n",
      "63/63 - 3s - 47ms/step - accuracy: 0.8487 - loss: 0.5024 - val_accuracy: 0.7820 - val_loss: 0.7135\n",
      "Epoch 11/30\n",
      "63/63 - 3s - 47ms/step - accuracy: 0.8587 - loss: 0.4647 - val_accuracy: 0.7910 - val_loss: 0.6458\n",
      "Epoch 12/30\n",
      "63/63 - 3s - 48ms/step - accuracy: 0.8707 - loss: 0.4336 - val_accuracy: 0.7854 - val_loss: 0.6822\n",
      "Epoch 13/30\n",
      "63/63 - 3s - 47ms/step - accuracy: 0.8822 - loss: 0.4087 - val_accuracy: 0.7978 - val_loss: 0.6640\n",
      "Epoch 14/30\n",
      "63/63 - 3s - 48ms/step - accuracy: 0.8915 - loss: 0.3922 - val_accuracy: 0.8236 - val_loss: 0.5957\n",
      "Epoch 15/30\n",
      "63/63 - 3s - 48ms/step - accuracy: 0.9018 - loss: 0.3629 - val_accuracy: 0.7831 - val_loss: 0.7093\n",
      "Epoch 16/30\n",
      "63/63 - 3s - 46ms/step - accuracy: 0.9016 - loss: 0.3524 - val_accuracy: 0.8494 - val_loss: 0.5090\n",
      "Epoch 17/30\n",
      "63/63 - 3s - 49ms/step - accuracy: 0.9031 - loss: 0.3544 - val_accuracy: 0.8202 - val_loss: 0.5627\n",
      "Epoch 18/30\n",
      "63/63 - 3s - 49ms/step - accuracy: 0.9045 - loss: 0.3370 - val_accuracy: 0.7663 - val_loss: 0.7761\n",
      "Epoch 19/30\n",
      "63/63 - 3s - 47ms/step - accuracy: 0.9113 - loss: 0.3212 - val_accuracy: 0.8483 - val_loss: 0.5073\n",
      "Epoch 20/30\n",
      "63/63 - 3s - 52ms/step - accuracy: 0.9214 - loss: 0.2902 - val_accuracy: 0.8303 - val_loss: 0.5827\n",
      "Epoch 21/30\n",
      "63/63 - 3s - 48ms/step - accuracy: 0.9294 - loss: 0.2781 - val_accuracy: 0.8045 - val_loss: 0.6521\n",
      "Epoch 22/30\n",
      "63/63 - 3s - 49ms/step - accuracy: 0.9265 - loss: 0.2792 - val_accuracy: 0.8393 - val_loss: 0.5813\n",
      "Epoch 23/30\n",
      "63/63 - 3s - 48ms/step - accuracy: 0.9286 - loss: 0.2775 - val_accuracy: 0.8371 - val_loss: 0.5502\n",
      "Epoch 24/30\n",
      "63/63 - 3s - 48ms/step - accuracy: 0.9378 - loss: 0.2656 - val_accuracy: 0.8371 - val_loss: 0.5444\n",
      "Epoch 25/30\n",
      "63/63 - 3s - 49ms/step - accuracy: 0.9448 - loss: 0.2387 - val_accuracy: 0.8551 - val_loss: 0.5103\n",
      "Epoch 26/30\n",
      "63/63 - 3s - 47ms/step - accuracy: 0.9435 - loss: 0.2354 - val_accuracy: 0.8202 - val_loss: 0.6749\n",
      "Epoch 27/30\n",
      "63/63 - 3s - 48ms/step - accuracy: 0.9418 - loss: 0.2445 - val_accuracy: 0.8539 - val_loss: 0.5785\n",
      "Epoch 28/30\n",
      "63/63 - 3s - 50ms/step - accuracy: 0.9429 - loss: 0.2415 - val_accuracy: 0.8472 - val_loss: 0.5506\n",
      "Epoch 29/30\n",
      "63/63 - 3s - 47ms/step - accuracy: 0.9495 - loss: 0.2230 - val_accuracy: 0.8247 - val_loss: 0.6437\n",
      "Epoch 30/30\n",
      "63/63 - 3s - 49ms/step - accuracy: 0.9578 - loss: 0.2102 - val_accuracy: 0.8573 - val_loss: 0.5240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3c3ee5b50>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_train, y_train, batch_size=128, epochs=30, validation_split=0.1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 - 0s - 3ms/step - accuracy: 0.8593 - loss: 0.5269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5269291996955872, 0.8592625856399536]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_val, y_val, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('cnn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "cnn.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_predictor = ModelPredictior(model_path='cnn_model.keras', input_shape=(13, 130, 1), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blues': 14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 12:12:35.003038: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Matrix size-incompatible: In[0]: [1,1280], In[1]: [1920,128]\n",
      "\t [[{{node sequential_3_1/dense_9_1/MatMul}}]]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./Music Genre Classification/Train/blues/blues.00039.wav\"\n",
    "\n",
    "predicted_genres = CNN_predictor.cnn_predict(file_path)\n",
    "print(predicted_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_freq_genre(genres):\n",
    "    max_freq = 0\n",
    "    max_genre = ''\n",
    "    for genre in genres.keys():\n",
    "        if genres[genre] > max_freq:\n",
    "            max_freq = genres[genre]\n",
    "            max_genre = genre\n",
    "    return max_genre\n",
    "\n",
    "predictions = []\n",
    "actual = []\n",
    "for i, file in enumerate(test_files):\n",
    "    try:\n",
    "        predicted_genres = CNN_predictor.cnn_predict(file)\n",
    "        predictions.append(max_freq_genre(predicted_genres))\n",
    "        actual.append(file.split(\"/\")[-2])\n",
    "    except Exception as e:\n",
    "        print(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.00      0.00      0.00         0\n",
      "       blues       0.80      1.00      0.89        20\n",
      "   classical       1.00      1.00      1.00        20\n",
      "     country       1.00      0.90      0.95        20\n",
      "       disco       0.87      1.00      0.93        20\n",
      "      hiphop       0.95      1.00      0.98        20\n",
      "        jazz       1.00      1.00      1.00        20\n",
      "       metal       1.00      0.70      0.82        20\n",
      "         pop       1.00      0.90      0.95        20\n",
      "      reggae       0.95      0.90      0.92        20\n",
      "        rock       0.86      0.90      0.88        20\n",
      "\n",
      "    accuracy                           0.93       200\n",
      "   macro avg       0.86      0.85      0.85       200\n",
      "weighted avg       0.94      0.93      0.93       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print((classification_report(actual, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open('encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jazz\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xidx = 0\n",
    "yidx = 10\n",
    "genre = 'jazz'\n",
    "print(genre)\n",
    "for i in range (20, 60):\n",
    "    \n",
    "    file_name = f\"./Music Genre Classification/Train/{genre}/{genre}.000{i}.wav\"\n",
    "    try:\n",
    "        audio, sr = sf.read(file_name)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "    MFCC = librosa.feature.mfcc(y=audio, n_mfcc=data_extractor.n_mfccs, n_fft=data_extractor.n_fft, hop_length=data_extractor.hop_length)\n",
    "    MFCC = np.mean(MFCC, axis=1)\n",
    "    MFCC = scaler.transform(MFCC[np.newaxis, :])\n",
    "    if i > 39:\n",
    "        plt.scatter(MFCC[0][xidx], MFCC[0][yidx], marker='x', c='red')\n",
    "        plt.xlabel(f\"MFCC {xidx}\")\n",
    "        plt.ylabel(f\"MFCC {yidx}\")\n",
    "    else:\n",
    "        plt.scatter(MFCC[0][xidx], MFCC[0][yidx], marker='o', c='blue')\n",
    "        plt.xlabel(f\"MFCC {xidx}\")\n",
    "        plt.ylabel(f\"MFCC {yidx}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
